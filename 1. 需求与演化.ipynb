{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目需求分析\n",
    "\n",
    "### 1. 客户需求\n",
    "- 快速完成概念验证(PoC)\n",
    "- 通过图形界面快速完成演示\n",
    "- 本地私有数据\n",
    "- 对比不同模型和成本，决定如何部署\n",
    "\n",
    "### 2. LlamaIndex的优势和问题\n",
    "\n",
    "#### 2.1 LlamaIndex 的优势\n",
    "- 丰富的工具 [llamahub](https://llamahub.ai/)\n",
    "- 完善的文档和教程 [docs](https://docs.llamaindex.ai/en/stable/)\n",
    "\n",
    "#### 2.2 LlamaIndex 的问题\n",
    "- 缺乏图形界面，操作不够直观\n",
    "- 默认RAG实现存在多个问题点，需要手工优化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解决思路\n",
    "\n",
    "1. 为了实现用户需求，先增加前端再打补丁\n",
    "2. 直接从开源项目中借鉴\n",
    "\n",
    "#### 思考1 用官方的Demo\n",
    "\n",
    "\n",
    "[putting it all together](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/apps/)\n",
    "\n",
    "问题：\n",
    "Flask Backend + React Frontend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@app.route(\"/query\", methods=[\"GET\"])\n",
    "def query_index():\n",
    "    pass\n",
    "\n",
    "@app.route(\"/uploadFile\", methods=[\"POST\"])\n",
    "def upload_file():\n",
    "    pass\n",
    "    \n",
    "@app.route(\"/getDocuments\", methods=[\"GET\"])\n",
    "def get_documents():\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_index()\n",
    "\n",
    "    # ... ...\n",
    "\n",
    "    server = manager.get_server()\n",
    "\n",
    "    print(\"server started...\")\n",
    "    server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：\n",
    "1. 框架：\n",
    "2. 成本：\n",
    "3. 性能：\n",
    "\n",
    "\n",
    "#### 思考2 \n",
    "- 全栈 Python \n",
    "- 方便替换模型 兼容 OpenAI API 的国内大模型\n",
    "- 演示直观\n",
    "\n",
    "[百炼本地知识库方案](https://help.aliyun.com/zh/model-studio/use-cases/build-rag-application-based-on-local-retrieval?spm=a2c4g.11186623.help-menu-2400256.d_2_3.2490b0a82sTD22)\n",
    "\n",
    "解决方案： FastAPI + Gradio + Llamaindex + qwen-plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_block():\n",
    "    pass\n",
    "\n",
    "def get_upload_block():\n",
    "    pass\n",
    "\n",
    "def get_knowledge_base_block():\n",
    "    pass\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "def read_main():\n",
    "    html_content = main_html\n",
    "    return HTMLResponse(content=html_content)\n",
    "\n",
    "\n",
    "app = gr.mount_gradio_app(app, get_chat_block(), path=\"/chat\")\n",
    "app = gr.mount_gradio_app(app, get_upload_block(), path=\"/upload_data\")\n",
    "app = gr.mount_gradio_app(app, get_knowledge_base_block(), path=\"/create_knowledge_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 增加法律数据集测试，并阅读代码\n",
    "\n",
    "[📚法律数据](https://github.com/pengxiao-song/awesome-chinese-legal-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 尝试本地模型\n",
    "\n",
    "#### 4.1 增加 LLMs 网关( LLMs GateWay)，尝试 chat 模型，便于比较合测试\n",
    "\n",
    "1. Qwen plus\n",
    "2. qwen 2.5 - 7b\n",
    "3. DeepSeek V3\n",
    "\n",
    "#### 4.2 尝试本地 embedding 模型\n",
    "\n",
    "最著名的几个中文embedding模型：\n",
    "\n",
    "1. GTE 通义实验室\n",
    "2. BGE是由北京智源人工智能研究院提出的新的embedding模型。 源码地址：https://github.com/FlagOpen/FlagEmbedding\n",
    "3. BCE 网易有道的 BCEmbedding 模型的GitHub官网 https://github.com/netease-youdao/BCEmbedding\n",
    "4. M3E 是 Moka Massive Mixed Embedding 的缩写 ，此模型由 MokaAI 训练，开源和评测，训练脚本使用 uniem ，评测 BenchMark 使用 MTEB-zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 小结\n",
    "\n",
    "1. 本地 embedding 模型不影响召回效率， CPU 性能足够，建议采用\n",
    "2. 本地 (chat)大模型对内容的理解非常有限，实际工作中可以采用 LLMs Gateway 切换，RAG环境建议采用在线的模型\n",
    "3. FastAPI + Gradio + Llamaindex + qwen-plus 全栈 Python 可以实现较好的 PoC 基本需要，但是在 RAG 整个过程都需要打补丁"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
