{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é¡¹ç›®éœ€æ±‚åˆ†æ\n",
    "\n",
    "### 1. å®¢æˆ·éœ€æ±‚\n",
    "- å¿«é€Ÿå®Œæˆæ¦‚å¿µéªŒè¯(PoC)\n",
    "- é€šè¿‡å›¾å½¢ç•Œé¢å¿«é€Ÿå®Œæˆæ¼”ç¤º\n",
    "- æœ¬åœ°ç§æœ‰æ•°æ®\n",
    "- å¯¹æ¯”ä¸åŒæ¨¡å‹å’Œæˆæœ¬ï¼Œå†³å®šå¦‚ä½•éƒ¨ç½²\n",
    "\n",
    "### 2. LlamaIndexçš„ä¼˜åŠ¿å’Œé—®é¢˜\n",
    "\n",
    "#### 2.1 LlamaIndex çš„ä¼˜åŠ¿\n",
    "- ä¸°å¯Œçš„å·¥å…· [llamahub](https://llamahub.ai/)\n",
    "- å®Œå–„çš„æ–‡æ¡£å’Œæ•™ç¨‹ [docs](https://docs.llamaindex.ai/en/stable/)\n",
    "\n",
    "#### 2.2 LlamaIndex çš„é—®é¢˜\n",
    "- ç¼ºä¹å›¾å½¢ç•Œé¢ï¼Œæ“ä½œä¸å¤Ÿç›´è§‚\n",
    "- é»˜è®¤RAGå®ç°å­˜åœ¨å¤šä¸ªé—®é¢˜ç‚¹ï¼Œéœ€è¦æ‰‹å·¥ä¼˜åŒ–\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è§£å†³æ€è·¯\n",
    "\n",
    "1. ä¸ºäº†å®ç°ç”¨æˆ·éœ€æ±‚ï¼Œå…ˆå¢åŠ å‰ç«¯å†æ‰“è¡¥ä¸\n",
    "2. ç›´æ¥ä»å¼€æºé¡¹ç›®ä¸­å€Ÿé‰´\n",
    "\n",
    "#### æ€è€ƒ1 ç”¨å®˜æ–¹çš„Demo\n",
    "\n",
    "\n",
    "[putting it all together](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/apps/)\n",
    "\n",
    "é—®é¢˜ï¼š\n",
    "Flask Backend + React Frontend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@app.route(\"/query\", methods=[\"GET\"])\n",
    "def query_index():\n",
    "    pass\n",
    "\n",
    "@app.route(\"/uploadFile\", methods=[\"POST\"])\n",
    "def upload_file():\n",
    "    pass\n",
    "    \n",
    "@app.route(\"/getDocuments\", methods=[\"GET\"])\n",
    "def get_documents():\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_index()\n",
    "\n",
    "    # ... ...\n",
    "\n",
    "    server = manager.get_server()\n",
    "\n",
    "    print(\"server started...\")\n",
    "    server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç»“è®ºï¼š\n",
    "1. æ¡†æ¶ï¼š\n",
    "2. æˆæœ¬ï¼š\n",
    "3. æ€§èƒ½ï¼š\n",
    "\n",
    "\n",
    "#### æ€è€ƒ2 \n",
    "- å…¨æ ˆ Python \n",
    "- æ–¹ä¾¿æ›¿æ¢æ¨¡å‹ å…¼å®¹ OpenAI API çš„å›½å†…å¤§æ¨¡å‹\n",
    "- æ¼”ç¤ºç›´è§‚\n",
    "\n",
    "[ç™¾ç‚¼æœ¬åœ°çŸ¥è¯†åº“æ–¹æ¡ˆ](https://help.aliyun.com/zh/model-studio/use-cases/build-rag-application-based-on-local-retrieval?spm=a2c4g.11186623.help-menu-2400256.d_2_3.2490b0a82sTD22)\n",
    "\n",
    "è§£å†³æ–¹æ¡ˆï¼š FastAPI + Gradio + Llamaindex + qwen-plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_block():\n",
    "    pass\n",
    "\n",
    "def get_upload_block():\n",
    "    pass\n",
    "\n",
    "def get_knowledge_base_block():\n",
    "    pass\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "def read_main():\n",
    "    html_content = main_html\n",
    "    return HTMLResponse(content=html_content)\n",
    "\n",
    "\n",
    "app = gr.mount_gradio_app(app, get_chat_block(), path=\"/chat\")\n",
    "app = gr.mount_gradio_app(app, get_upload_block(), path=\"/upload_data\")\n",
    "app = gr.mount_gradio_app(app, get_knowledge_base_block(), path=\"/create_knowledge_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. å¢åŠ æ³•å¾‹æ•°æ®é›†æµ‹è¯•ï¼Œå¹¶é˜…è¯»ä»£ç \n",
    "\n",
    "[ğŸ“šæ³•å¾‹æ•°æ®](https://github.com/pengxiao-song/awesome-chinese-legal-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. å°è¯•æœ¬åœ°æ¨¡å‹\n",
    "\n",
    "#### 4.1 å¢åŠ  LLMs ç½‘å…³( LLMs GateWay)ï¼Œå°è¯• chat æ¨¡å‹ï¼Œä¾¿äºæ¯”è¾ƒåˆæµ‹è¯•\n",
    "\n",
    "1. Qwen plus\n",
    "2. qwen 2.5 - 7b\n",
    "3. DeepSeek V3\n",
    "\n",
    "#### 4.2 å°è¯•æœ¬åœ° embedding æ¨¡å‹\n",
    "\n",
    "æœ€è‘—åçš„å‡ ä¸ªä¸­æ–‡embeddingæ¨¡å‹ï¼š\n",
    "\n",
    "1. GTE é€šä¹‰å®éªŒå®¤\n",
    "2. BGEæ˜¯ç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢æå‡ºçš„æ–°çš„embeddingæ¨¡å‹ã€‚ æºç åœ°å€ï¼šhttps://github.com/FlagOpen/FlagEmbedding\n",
    "3. BCE ç½‘æ˜“æœ‰é“çš„ BCEmbedding æ¨¡å‹çš„GitHubå®˜ç½‘ https://github.com/netease-youdao/BCEmbedding\n",
    "4. M3E æ˜¯ Moka Massive Mixed Embedding çš„ç¼©å†™ ï¼Œæ­¤æ¨¡å‹ç”± MokaAI è®­ç»ƒï¼Œå¼€æºå’Œè¯„æµ‹ï¼Œè®­ç»ƒè„šæœ¬ä½¿ç”¨ uniem ï¼Œè¯„æµ‹ BenchMark ä½¿ç”¨ MTEB-zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. å°ç»“\n",
    "\n",
    "1. æœ¬åœ° embedding æ¨¡å‹ä¸å½±å“å¬å›æ•ˆç‡ï¼Œ CPU æ€§èƒ½è¶³å¤Ÿï¼Œå»ºè®®é‡‡ç”¨\n",
    "2. æœ¬åœ° (chat)å¤§æ¨¡å‹å¯¹å†…å®¹çš„ç†è§£éå¸¸æœ‰é™ï¼Œå®é™…å·¥ä½œä¸­å¯ä»¥é‡‡ç”¨ LLMs Gateway åˆ‡æ¢ï¼ŒRAGç¯å¢ƒå»ºè®®é‡‡ç”¨åœ¨çº¿çš„æ¨¡å‹\n",
    "3. FastAPI + Gradio + Llamaindex + qwen-plus å…¨æ ˆ Python å¯ä»¥å®ç°è¾ƒå¥½çš„ PoC åŸºæœ¬éœ€è¦ï¼Œä½†æ˜¯åœ¨ RAG æ•´ä¸ªè¿‡ç¨‹éƒ½éœ€è¦æ‰“è¡¥ä¸"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
